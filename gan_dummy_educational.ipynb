{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan-dummy-educational.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1JtT9Q1dwUrS3XX3FnoD0U2J24R9t_1g3",
      "authorship_tag": "ABX9TyNmWbl9XX6qUpEq0sbI5vLS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/halilagin/gen-adv-net/blob/master/gan_dummy_educational.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckDMjYst3Z1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dbf9628f-5203-4774-c14c-17ae9d5be711"
      },
      "source": [
        "!pip install dill\n",
        "import dill\n",
        "from pathlib import Path\n",
        "import os\n",
        "root = Path(\"/content/drive/My Drive/root/colab/\")\n",
        "output_dir=Path(str(root.absolute())+\"/gan-dummy-educational-output\")\n",
        "os.makedirs(str(output_dir), exist_ok=True)\n",
        "\n",
        "session_file = str(root.absolute())+\"/gan-dummy-educational.db\"\n",
        "dill.load_session(session_file)\n",
        "\n",
        "#dill.dump_session(session_file)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (0.3.1.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReEkz47W34ao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c1925a1-d18a-40da-f0cb-3bf33c99a6be"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "%matplotlib inline\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4SjffdD4p7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAINING_SIZE=256\n",
        "BUFFER_SIZE = 200\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 2000\n",
        "noise_dim = 100\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQPxm0iP4K1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate a dataset whose elemnts are one of [[1,1],[-1,1],[-1,-1],[1,-1]]\n",
        "fourpoints_set = tf.tile(tf.constant([[1,1],[-1,1],[-1,-1],[1,-1]]), [TRAINING_SIZE//8,1])\n",
        "\n",
        "#generate a dataset whose elemnts are points of a circled centered at (0,0)\n",
        "pi_ = tf.reshape(tf.linspace(-np.pi,np.pi,TRAINING_SIZE//2),[TRAINING_SIZE//2,1])\n",
        "circle_set = tf.concat([tf.cos(pi_),tf.sin(pi_)], -1)\n",
        "\n",
        "##generate square with corners [[1,1],[-1,1],[-1,-1],[1,-1]]\n",
        "line_size=TRAINING_SIZE//8\n",
        "square_upline_lr = tf.stack([tf.linspace(-1.,1.,line_size),tf.constant([1.0]*line_size)],axis=-1)\n",
        "square_rightline_tb = tf.stack([tf.constant([1.0]*line_size),tf.linspace(1.,-1.,line_size),],axis=-1)\n",
        "square_botline_rl = tf.stack([tf.linspace(1.,-1.,line_size),tf.constant([-1.0]*line_size)],axis=-1)\n",
        "square_leftline_bt = tf.stack([tf.constant([-1.0]*line_size),tf.linspace(-1.,1.,line_size),],axis=-1)\n",
        "square_set = tf.concat([square_upline_lr,square_rightline_tb,square_botline_rl,square_leftline_bt],axis=0)\n",
        "\n",
        "#generate a dataset whose elemnts are points of a circled centered at (0,0)\n",
        "x2 = tf.reshape(tf.linspace(-1.,1.,TRAINING_SIZE//2),[TRAINING_SIZE//2,1])\n",
        "x2_set = tf.concat([x2,tf.constant(x2**2)], -1)\n",
        "\n",
        "\n",
        "datasets = {\n",
        "    \"fourpoints\":fourpoints_set,\n",
        "    \"circle\":circle_set,\n",
        "    \"square\":square_set,\n",
        "    \"x2\":x2_set\n",
        "}\n",
        "\n",
        "train_dataset_name=\"circle\"\n",
        "training_set = datasets[train_dataset_name]\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(tf.reshape(training_set, [1,16,16,1])).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po-jihDA75ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(4*4*64, use_bias=False, input_shape=(noise_dim,) ) )\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((4, 4 ,64)))\n",
        "    assert model.output_shape == (None, 4, 4, 64) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 8, 8, 32)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 16, 16, 1)\n",
        "\n",
        "    return model\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[16, 16, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model\n",
        "\n",
        "# This method returns a helper function to compute cross entropy loss\n",
        "#cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "cross_entropy = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()\n",
        "\n",
        "checkpoint_dir = './gan_dummy_training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n",
        "\n",
        "\n",
        "\n",
        "seed = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    predictions = model(test_input, training=False)\n",
        "    shape_ = predictions.shape #[batch_size, 16, 16, 1]\n",
        "    predictions = tf.reshape(predictions[0],[shape_[1]*shape_[2]//2,2])\n",
        "    \n",
        "    fig,ax = plt.subplots()\n",
        "    ax.axis('equal')\n",
        "    ax.set_xlim([-1.1,1.1])\n",
        "    ax.set_ylim([-1.1,1.1])\n",
        "    ax.scatter(predictions[:, 0],predictions[:, 1], c='gray')\n",
        "    #data_ = tf.constant([[1,1],[-1,1],[-1,-1],[1,-1]])\n",
        "    #ax.scatter(data_[:,0],data_[:,1], c=\"r\", s=25)\n",
        "    ax.scatter(training_set[:,0],training_set[:,1])\n",
        "    plt.axis('off')\n",
        "    plt.savefig(str(output_dir)+'/{0}_image_at_epoch_{1:04d}.png'.format(train_dataset_name,epoch))\n",
        "    plt.close(fig) \n",
        "    #plt.show()\n",
        "\n",
        "#@tf.function\n",
        "def train(dataset, epochs):\n",
        "    generate_and_save_images(generator, 0, seed)\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        for image_batch in dataset:\n",
        "            train_step(image_batch)\n",
        "\n",
        "        # Produce images for the GIF as we go\n",
        "        #display.clear_output(wait=True)\n",
        "        \n",
        "        # Save the model every 15 epochs\n",
        "        if (epoch + 1) % 40 == 0:\n",
        "          generate_and_save_images(generator, epoch + 1, seed)\n",
        "          checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "          print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "    generate_and_save_images(generator, epochs+1, seed)\n",
        "\n",
        "    # Generate after the final epoch\n",
        "    #display.clear_output(wait=True)\n",
        "    #generate_and_save_images(generator, epochs, seed)\n",
        "  "
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXJr-r42uzH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "9de209af-f7b0-40b9-d3e5-835fcf7eadc0"
      },
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 40 is 0.2227933406829834 sec\n",
            "Time for epoch 80 is 0.22194647789001465 sec\n",
            "Time for epoch 120 is 0.22320866584777832 sec\n",
            "Time for epoch 160 is 0.2252638339996338 sec\n",
            "Time for epoch 200 is 0.23028230667114258 sec\n",
            "Time for epoch 240 is 0.21278715133666992 sec\n",
            "Time for epoch 280 is 0.22409915924072266 sec\n",
            "Time for epoch 320 is 0.21778202056884766 sec\n",
            "Time for epoch 360 is 0.22771048545837402 sec\n",
            "Time for epoch 400 is 0.21193671226501465 sec\n",
            "Time for epoch 440 is 0.2294473648071289 sec\n",
            "Time for epoch 480 is 0.2232227325439453 sec\n",
            "Time for epoch 520 is 0.226304292678833 sec\n",
            "Time for epoch 560 is 0.22312092781066895 sec\n",
            "Time for epoch 600 is 0.21706390380859375 sec\n",
            "Time for epoch 640 is 0.21593618392944336 sec\n",
            "Time for epoch 680 is 0.21481943130493164 sec\n",
            "Time for epoch 720 is 0.21309566497802734 sec\n",
            "Time for epoch 760 is 0.21375274658203125 sec\n",
            "Time for epoch 800 is 0.21391725540161133 sec\n",
            "Time for epoch 840 is 0.21647286415100098 sec\n",
            "Time for epoch 880 is 0.218536376953125 sec\n",
            "Time for epoch 920 is 0.2164769172668457 sec\n",
            "Time for epoch 960 is 0.22572016716003418 sec\n",
            "Time for epoch 1000 is 0.22347807884216309 sec\n",
            "Time for epoch 1040 is 0.22469329833984375 sec\n",
            "Time for epoch 1080 is 0.22115492820739746 sec\n",
            "Time for epoch 1120 is 0.2263965606689453 sec\n",
            "Time for epoch 1160 is 0.21744441986083984 sec\n",
            "Time for epoch 1200 is 0.22252583503723145 sec\n",
            "Time for epoch 1240 is 0.21053075790405273 sec\n",
            "Time for epoch 1280 is 0.21272826194763184 sec\n",
            "Time for epoch 1320 is 0.2005763053894043 sec\n",
            "Time for epoch 1360 is 0.21296238899230957 sec\n",
            "Time for epoch 1400 is 0.21427059173583984 sec\n",
            "Time for epoch 1440 is 0.21226096153259277 sec\n",
            "Time for epoch 1480 is 0.4766411781311035 sec\n",
            "Time for epoch 1520 is 0.22246456146240234 sec\n",
            "Time for epoch 1560 is 0.22527241706848145 sec\n",
            "Time for epoch 1600 is 0.21552824974060059 sec\n",
            "Time for epoch 1640 is 0.23762297630310059 sec\n",
            "Time for epoch 1680 is 0.20476484298706055 sec\n",
            "Time for epoch 1720 is 0.20241045951843262 sec\n",
            "Time for epoch 1760 is 0.21525239944458008 sec\n",
            "Time for epoch 1800 is 0.22181272506713867 sec\n",
            "Time for epoch 1840 is 0.23086094856262207 sec\n",
            "Time for epoch 1880 is 0.20337414741516113 sec\n",
            "Time for epoch 1920 is 0.21557140350341797 sec\n",
            "Time for epoch 1960 is 0.2011556625366211 sec\n",
            "Time for epoch 2000 is 0.20231175422668457 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlCiJDSGDyux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2bbce875-db9d-4a2e-9c04-8846e11ac002"
      },
      "source": [
        "import imageio\n",
        "#    plt.savefig(str(output_dir)+'/{0}_image_at_epoch_{1:04d}.png'.format(train_dataset_name,epoch))\n",
        "\n",
        "def create_movie(dsname):\n",
        "  gifpath=str(output_dir)+\"/{0}.gif\".format(dsname)\n",
        "  with imageio.get_writer(gifpath, mode='I', fps=2) as writer:\n",
        "    for epoch in np.arange(0,EPOCHS+40,40):\n",
        "      filename = str(output_dir)+'/{0}_image_at_epoch_{1:04d}.png'.format(dsname,epoch)\n",
        "      image = imageio.imread(filename)\n",
        "      writer.append_data(image)\n",
        "  return gifpath\n",
        "\n",
        "#mergeed_images data set name:\n",
        "#['circle', 'fourpoints', 'square', 'x2']\n",
        "dsnames = sorted(list(datasets.keys()))\n",
        "gifpath = create_movie(\"000_merge\")\n",
        "gifpath"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/root/colab/gan-dummy-educational-output/000_merge.gif'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUrQcR4_WaEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d35460d-ad5d-4352-ec38-44689e866a93"
      },
      "source": [
        "!ls /content/drive/My\\ Drive/root/colab/gan-dummy-educational-output/000_merge.gif"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/drive/My Drive/root/colab/gan-dummy-educational-output/000_merge.gif'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5R-optcHLuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "\n",
        "def merge_gan_progress():\n",
        "  \n",
        "  def merge_one_epoch(epoch, dsnames):\n",
        "    fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2,figsize=(8,8))\n",
        "    #fig.suptitle(\"Epoch:{0}\".format(epoch), fontsize=\"x-large\")\n",
        "    fig.text(0.5, 0.95, 'Approximating to four functions with Generative Adversarial Networks', transform=fig.transFigure, horizontalalignment='center',fontsize=\"x-large\")\n",
        "    fig.text(0.5, 0.91, \"Epoch:{0}\".format(epoch), transform=fig.transFigure, horizontalalignment='center',fontsize=\"x-large\")\n",
        "\n",
        "    axes = [ax1,ax2,ax3,ax4]\n",
        "    for ax_ in axes:\n",
        "      ax_.set_aspect(aspect=\"equal\", adjustable=\"box\",  share=False)\n",
        "    for i in range(4):\n",
        "      image_filepath = str(output_dir)+'/{0}_image_at_epoch_{1:04d}.png'.format(dsnames[i],epoch)\n",
        "      \n",
        "      axes[i].set_xticks([]) \n",
        "      axes[i].set_yticks([]) \n",
        "      # axes[i].set_xlim([-1.1,1.1])\n",
        "      # axes[i].set_ylim([-1.1,1.1])\n",
        "      axes[i].imshow(mpimg.imread(image_filepath))\n",
        "    #plt.axis('off')\n",
        "    merge_image = str(output_dir)+'/000_merge_image_at_epoch_{0:04d}.png'.format(epoch)\n",
        "    plt.savefig(merge_image)\n",
        "    plt.close(fig) \n",
        "    \n",
        "  for epoch in np.arange(0,EPOCHS+40,40):\n",
        "    merge_one_epoch(epoch, dsnames)\n",
        "\n",
        "merge_gan_progress()    "
      ],
      "execution_count": 111,
      "outputs": []
    }
  ]
}